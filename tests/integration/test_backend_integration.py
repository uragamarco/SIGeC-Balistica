#!/usr/bin/env python3
"""
Tests de Integraci√≥n Backend Consolidados - SIGeC-Balistica
===========================================================

Suite completa de tests de integraci√≥n backend que consolida:
- test_backend_integration_consolidated.py
- test_basic_integration.py  
- legacy_backup/test_backend_integration.py

Valida la integraci√≥n completa del backend incluyendo:
- M√≥dulos de procesamiento de im√°genes
- Base de datos y operaciones CRUD
- Sistema de matching y comparaci√≥n
- Pipeline unificado y cache inteligente
- Gesti√≥n de configuraci√≥n y dependencias
- Manejo de errores y validaci√≥n del sistema

Autor: SIGeC-Balistica Team
Fecha: Octubre 2025
"""

import sys
import os
import time
import traceback
import tempfile
import numpy as np
import json
import pytest
from pathlib import Path
from typing import Dict, Any, List, Optional
import unittest
from unittest.mock import Mock, patch, MagicMock
from datetime import datetime

# Agregar el directorio ra√≠z al path
sys.path.insert(0, str(Path(__file__).parent.parent))

# Imports del sistema
try:
    from config.unified_config import get_unified_config
    CONFIG_AVAILABLE = True
except ImportError:
    CONFIG_AVAILABLE = False
    get_unified_config = Mock()

try:
    from utils.logger import setup_logging, get_logger
    from utils.validators import SystemValidator, SecurityUtils, FileUtils
    from utils.dependency_manager import DependencyManager
    UTILS_AVAILABLE = True
except ImportError:
    UTILS_AVAILABLE = False
    setup_logging = Mock()
    get_logger = Mock()

# Procesamiento de im√°genes
try:
    from image_processing.feature_extractor import BallisticFeatureExtractor
    from image_processing.unified_roi_detector import UnifiedROIDetector
    from image_processing.statistical_analyzer import StatisticalAnalyzer
    from image_processing.unified_preprocessor import UnifiedPreprocessor
    IMAGE_PROCESSING_AVAILABLE = True
except ImportError:
    IMAGE_PROCESSING_AVAILABLE = False
    BallisticFeatureExtractor = Mock
    UnifiedROIDetector = Mock
    StatisticalAnalyzer = Mock
    UnifiedPreprocessor = Mock

# Base de datos
try:
    from database.vector_db import VectorDatabase, BallisticCase, BallisticImage, FeatureVector
    DATABASE_AVAILABLE = True
except ImportError:
    DATABASE_AVAILABLE = False
    VectorDatabase = Mock
    BallisticCase = Mock
    BallisticImage = Mock
    FeatureVector = Mock

# Matching
try:
    from matching.unified_matcher import UnifiedMatcher
    MATCHING_AVAILABLE = True
except ImportError:
    MATCHING_AVAILABLE = False
    UnifiedMatcher = Mock

# Core
try:
    from core.unified_pipeline import UnifiedPipeline
    from core.intelligent_cache import IntelligentCache
    CORE_AVAILABLE = True
except ImportError:
    CORE_AVAILABLE = False
    UnifiedPipeline = Mock
    IntelligentCache = Mock


class BackendIntegrationTestSuite(unittest.TestCase):
    """Suite consolidada de tests de integraci√≥n backend"""
    
    @classmethod
    def setUpClass(cls):
        """Configuraci√≥n inicial de la clase de tests"""
        cls.logger = get_logger(__name__) if UTILS_AVAILABLE else Mock()
        cls.config = get_unified_config() if CONFIG_AVAILABLE else {}
        cls.test_results = {
            'timestamp': datetime.now().isoformat(),
            'tests_executed': [],
            'summary': {
                'total': 0,
                'passed': 0,
                'failed': 0,
                'skipped': 0
            }
        }
        
        # Configurar directorio temporal para tests
        cls.temp_dir = tempfile.mkdtemp(prefix='sigec_backend_test_')
        
        print(f"üîß Configurando tests de integraci√≥n backend...")
        print(f"üìÅ Directorio temporal: {cls.temp_dir}")
        
    @classmethod
    def tearDownClass(cls):
        """Limpieza final de la clase de tests"""
        import shutil
        if hasattr(cls, 'temp_dir') and os.path.exists(cls.temp_dir):
            shutil.rmtree(cls.temp_dir, ignore_errors=True)
        
        # Imprimir resumen final
        summary = cls.test_results['summary']
        print(f"\nüìä RESUMEN DE TESTS BACKEND:")
        print(f"   Total: {summary['total']}")
        print(f"   ‚úÖ Pasados: {summary['passed']}")
        print(f"   ‚ùå Fallidos: {summary['failed']}")
        print(f"   ‚è≠Ô∏è Saltados: {summary['skipped']}")
    
    def setUp(self):
        """Configuraci√≥n antes de cada test"""
        self.start_time = time.time()
        
    def tearDown(self):
        """Limpieza despu√©s de cada test"""
        execution_time = time.time() - self.start_time
        test_name = self._testMethodName
        
        # Registrar resultado del test
        self.test_results['tests_executed'].append({
            'name': test_name,
            'execution_time': execution_time,
            'timestamp': datetime.now().isoformat()
        })
        
        self.test_results['summary']['total'] += 1
        
    def test_project_structure_validation(self):
        """Verificar estructura del proyecto backend"""
        print("üîç Validando estructura del proyecto...")
        
        try:
            # Ra√≠z del proyecto (subir 3 niveles desde este archivo)
            project_root = Path(__file__).resolve().parent.parent.parent
            
            # Verificar directorios principales del backend
            expected_dirs = [
                'config',
                'utils', 
                'image_processing',
                'database',
                'matching',
                'core',
                'tests'
            ]
            
            missing_dirs = []
            for dir_name in expected_dirs:
                dir_path = project_root / dir_name
                if not dir_path.exists():
                    missing_dirs.append(dir_name)
                elif not dir_path.is_dir():
                    missing_dirs.append(f"{dir_name} (no es directorio)")
            
            if missing_dirs:
                self.test_results['summary']['failed'] += 1
                self.fail(f"Directorios faltantes: {missing_dirs}")
            else:
                self.test_results['summary']['passed'] += 1
                print("  ‚úÖ Estructura del proyecto v√°lida")
                
        except Exception as e:
            self.test_results['summary']['failed'] += 1
            self.fail(f"Error validando estructura: {e}")
    
    def test_module_imports(self):
        """Verificar que los m√≥dulos principales se pueden importar"""
        print("üîç Probando imports de m√≥dulos...")
        
        import_results = {
            'config': CONFIG_AVAILABLE,
            'utils': UTILS_AVAILABLE,
            'image_processing': IMAGE_PROCESSING_AVAILABLE,
            'database': DATABASE_AVAILABLE,
            'matching': MATCHING_AVAILABLE,
            'core': CORE_AVAILABLE
        }
        
        failed_imports = [module for module, available in import_results.items() if not available]
        
        if failed_imports:
            print(f"  ‚ö†Ô∏è M√≥dulos no disponibles: {failed_imports}")
            self.test_results['summary']['skipped'] += 1
            self.skipTest(f"M√≥dulos no disponibles: {failed_imports}")
        else:
            self.test_results['summary']['passed'] += 1
            print("  ‚úÖ Todos los m√≥dulos importados correctamente")
    
    def test_configuration_system(self):
        """Probar el sistema de configuraci√≥n"""
        print("üîç Probando sistema de configuraci√≥n...")
        
        if not CONFIG_AVAILABLE:
            self.test_results['summary']['skipped'] += 1
            self.skipTest("Sistema de configuraci√≥n no disponible")
            
        try:
            # Aceptar objeto UnifiedConfig y convertir a dict si es necesario
            config_obj = get_unified_config()
            config = config_obj if isinstance(config_obj, dict) else (config_obj.get_config_dict() if hasattr(config_obj, 'get_config_dict') else {})
            
            # Verificar que la configuraci√≥n es un diccionario
            self.assertIsInstance(config, dict, "La configuraci√≥n debe ser un diccionario o convertible mediante get_config_dict")
            
            # Verificar secciones b√°sicas esperadas
            expected_sections = ['database', 'image_processing', 'matching', 'logging']
            available_sections = [section for section in expected_sections if section in config]
            
            print(f"  üìã Secciones disponibles: {available_sections}")
            
            self.test_results['summary']['passed'] += 1
            print("  ‚úÖ Sistema de configuraci√≥n funcionando")
            
        except Exception as e:
            self.test_results['summary']['failed'] += 1
            self.fail(f"Error en sistema de configuraci√≥n: {e}")
    
    def test_database_module(self):
        """Probar el m√≥dulo de base de datos"""
        print("üîç Probando m√≥dulo de base de datos...")
        
        if not DATABASE_AVAILABLE:
            self.test_results['summary']['skipped'] += 1
            self.skipTest("M√≥dulo de base de datos no disponible")
            
        try:
            # Crear configuraci√≥n para la base de datos
            config = self.config if CONFIG_AVAILABLE else {
                'database': {
                    'path': os.path.join(self.temp_dir, 'test_db.sqlite'),
                    'faiss_path': os.path.join(self.temp_dir, 'test_faiss.index')
                }
            }
            
            # Inicializar base de datos
            db = VectorDatabase(config)
            
            # Verificar inicializaci√≥n
            self.assertIsNotNone(db, "Base de datos debe inicializarse")
            
            # Probar operaciones b√°sicas si no es mock
            if hasattr(db, 'db_path') and not isinstance(db, Mock):
                self.assertTrue(hasattr(db, 'db_path'), "DB debe tener ruta")
                print(f"  üìÅ Ruta de BD: {db.db_path}")
                
                if hasattr(db, 'faiss_path'):
                    print(f"  üìÅ Ruta FAISS: {db.faiss_path}")
            
            self.test_results['summary']['passed'] += 1
            print("  ‚úÖ M√≥dulo de base de datos funcionando")
            
        except Exception as e:
            self.test_results['summary']['failed'] += 1
            self.fail(f"Error en m√≥dulo de base de datos: {e}")
    
    def test_image_processing_module(self):
        """Probar el m√≥dulo de procesamiento de im√°genes"""
        print("üîç Probando m√≥dulo de procesamiento de im√°genes...")
        
        if not IMAGE_PROCESSING_AVAILABLE:
            self.test_results['summary']['skipped'] += 1
            self.skipTest("M√≥dulo de procesamiento de im√°genes no disponible")
            
        try:
            # Inicializar componentes principales
            extractor = BallisticFeatureExtractor()
            preprocessor = UnifiedPreprocessor()
            roi_detector = UnifiedROIDetector()
            
            # Verificar inicializaci√≥n
            self.assertIsNotNone(extractor, "Feature extractor debe inicializarse")
            self.assertIsNotNone(preprocessor, "Preprocessor debe inicializarse")
            self.assertIsNotNone(roi_detector, "ROI detector debe inicializarse")
            
            # Crear imagen de prueba
            test_image = np.random.randint(0, 255, (400, 400, 3), dtype=np.uint8)
            
            # Probar procesamiento b√°sico si no son mocks
            if not isinstance(preprocessor, Mock) and hasattr(preprocessor, 'preprocess'):
                try:
                    processed = preprocessor.preprocess(test_image)
                    self.assertIsNotNone(processed, "Imagen procesada no debe ser None")
                    print("  ‚úÖ Preprocesamiento funcionando")
                except Exception as e:
                    print(f"  ‚ö†Ô∏è Error en preprocesamiento: {e}")
            
            self.test_results['summary']['passed'] += 1
            print("  ‚úÖ M√≥dulo de procesamiento de im√°genes funcionando")
            
        except Exception as e:
            self.test_results['summary']['failed'] += 1
            self.fail(f"Error en m√≥dulo de procesamiento: {e}")
    
    def test_matching_module(self):
        """Probar el m√≥dulo de matching"""
        print("üîç Probando m√≥dulo de matching...")
        
        if not MATCHING_AVAILABLE:
            self.test_results['summary']['skipped'] += 1
            self.skipTest("M√≥dulo de matching no disponible")
            
        try:
            # Inicializar matcher
            matcher = UnifiedMatcher()
            
            # Verificar inicializaci√≥n
            self.assertIsNotNone(matcher, "Matcher debe inicializarse")
            
            # Crear datos de prueba
            features1 = np.random.rand(128).astype(np.float32)
            features2 = np.random.rand(128).astype(np.float32)
            
            # Probar matching b√°sico si no es mock
            if not isinstance(matcher, Mock) and hasattr(matcher, 'compare_features'):
                try:
                    similarity = matcher.compare_features(features1, features2)
                    self.assertIsInstance(similarity, (int, float), "Similarity debe ser num√©rico")
                    print(f"  üìä Similarity calculada: {similarity}")
                except Exception as e:
                    print(f"  ‚ö†Ô∏è Error en matching: {e}")
            
            self.test_results['summary']['passed'] += 1
            print("  ‚úÖ M√≥dulo de matching funcionando")
            
        except Exception as e:
            self.test_results['summary']['failed'] += 1
            self.fail(f"Error en m√≥dulo de matching: {e}")
    
    def test_core_pipeline(self):
        """Probar el pipeline unificado del core"""
        print("üîç Probando pipeline unificado...")
        
        if not CORE_AVAILABLE:
            self.test_results['summary']['skipped'] += 1
            self.skipTest("M√≥dulos core no disponibles")
            
        try:
            # Inicializar pipeline
            pipeline = UnifiedPipeline()
            
            # Verificar inicializaci√≥n
            self.assertIsNotNone(pipeline, "Pipeline debe inicializarse")
            
            # Probar cache inteligente
            cache = IntelligentCache()
            self.assertIsNotNone(cache, "Cache debe inicializarse")
            
            # Probar operaciones b√°sicas si no son mocks
            if not isinstance(pipeline, Mock):
                if hasattr(pipeline, 'process_image'):
                    print("  ‚úÖ Pipeline tiene m√©todo process_image")
                if hasattr(pipeline, 'extract_features'):
                    print("  ‚úÖ Pipeline tiene m√©todo extract_features")
            
            self.test_results['summary']['passed'] += 1
            print("  ‚úÖ Pipeline unificado funcionando")
            
        except Exception as e:
            self.test_results['summary']['failed'] += 1
            self.fail(f"Error en pipeline unificado: {e}")
    
    def test_error_handling(self):
        """Probar manejo de errores del sistema"""
        print("üîç Probando manejo de errores...")
        
        try:
            # Probar manejo de archivos inexistentes
            nonexistent_file = "/path/that/does/not/exist.jpg"
            
            # Verificar que el sistema maneja archivos inexistentes
            self.assertFalse(os.path.exists(nonexistent_file), "Archivo no debe existir")
            
            # Probar manejo de datos inv√°lidos
            invalid_data = None
            
            # El sistema debe manejar datos None sin crash
            if IMAGE_PROCESSING_AVAILABLE and not isinstance(UnifiedPreprocessor, Mock):
                try:
                    preprocessor = UnifiedPreprocessor()
                    if hasattr(preprocessor, 'preprocess'):
                        result = preprocessor.preprocess(invalid_data)
                        # Debe retornar None o lanzar excepci√≥n controlada
                        print("  ‚úÖ Manejo de datos None controlado")
                except Exception as e:
                    print(f"  ‚úÖ Excepci√≥n controlada para datos None: {type(e).__name__}")
            
            self.test_results['summary']['passed'] += 1
            print("  ‚úÖ Manejo de errores funcionando")
            
        except Exception as e:
            self.test_results['summary']['failed'] += 1
            self.fail(f"Error en manejo de errores: {e}")
    
    def test_integration_workflow(self):
        """Probar workflow completo de integraci√≥n"""
        print("üîç Probando workflow completo...")
        
        # Verificar disponibilidad de m√≥dulos necesarios
        required_modules = [
            ('config', CONFIG_AVAILABLE),
            ('image_processing', IMAGE_PROCESSING_AVAILABLE),
            ('database', DATABASE_AVAILABLE),
            ('matching', MATCHING_AVAILABLE)
        ]
        
        missing_modules = [name for name, available in required_modules if not available]
        
        if missing_modules:
            self.test_results['summary']['skipped'] += 1
            self.skipTest(f"M√≥dulos requeridos no disponibles: {missing_modules}")
        
        try:
            # 1. Configuraci√≥n
            config_obj = get_unified_config()
            config = config_obj if isinstance(config_obj, dict) else (config_obj.get_config_dict() if hasattr(config_obj, 'get_config_dict') else {})
            self.assertIsInstance(config, dict, "Config debe ser diccionario o convertible mediante get_config_dict")
            
            # 2. Crear imagen de prueba
            test_image = np.random.randint(0, 255, (400, 400, 3), dtype=np.uint8)
            
            # 3. Procesamiento
            if not isinstance(UnifiedPreprocessor, Mock):
                preprocessor = UnifiedPreprocessor()
                if hasattr(preprocessor, 'preprocess'):
                    processed_image = preprocessor.preprocess(test_image)
                    print("  ‚úÖ Imagen procesada")
            
            # 4. Extracci√≥n de caracter√≠sticas
            if not isinstance(BallisticFeatureExtractor, Mock):
                extractor = BallisticFeatureExtractor()
                if hasattr(extractor, 'extract_features'):
                    try:
                        features = extractor.extract_features(test_image)
                        print("  ‚úÖ Caracter√≠sticas extra√≠das")
                    except Exception as e:
                        print(f"  ‚ö†Ô∏è Error extrayendo caracter√≠sticas: {e}")
            
            # 5. Base de datos
            if not isinstance(VectorDatabase, Mock):
                db_config = config.get('database', {
                    'path': os.path.join(self.temp_dir, 'workflow_test.db')
                })
                db = VectorDatabase(db_config)
                print("  ‚úÖ Base de datos inicializada")
            
            self.test_results['summary']['passed'] += 1
            print("  ‚úÖ Workflow completo funcionando")
            
        except Exception as e:
            self.test_results['summary']['failed'] += 1
            self.fail(f"Error en workflow completo: {e}")
    
    def test_performance_basic(self):
        """Probar rendimiento b√°sico del sistema"""
        print("üîç Probando rendimiento b√°sico...")
        
        try:
            start_time = time.time()
            
            # Crear m√∫ltiples im√°genes de prueba
            test_images = []
            for i in range(5):
                img = np.random.randint(0, 255, (200, 200, 3), dtype=np.uint8)
                test_images.append(img)
            
            creation_time = time.time() - start_time
            
            # Procesar im√°genes si el m√≥dulo est√° disponible
            if IMAGE_PROCESSING_AVAILABLE and not isinstance(UnifiedPreprocessor, Mock):
                start_processing = time.time()
                preprocessor = UnifiedPreprocessor()
                
                processed_count = 0
                for img in test_images:
                    if hasattr(preprocessor, 'preprocess'):
                        try:
                            processed = preprocessor.preprocess(img)
                            processed_count += 1
                        except Exception:
                            pass
                
                processing_time = time.time() - start_processing
                
                print(f"  üìä Im√°genes creadas: 5 en {creation_time:.3f}s")
                print(f"  üìä Im√°genes procesadas: {processed_count} en {processing_time:.3f}s")
                
                # Verificar que el procesamiento no sea excesivamente lento
                if processing_time > 10:  # 10 segundos para 5 im√°genes peque√±as
                    print(f"  ‚ö†Ô∏è Procesamiento lento: {processing_time:.3f}s")
                else:
                    print(f"  ‚úÖ Rendimiento aceptable")
            
            self.test_results['summary']['passed'] += 1
            print("  ‚úÖ Test de rendimiento b√°sico completado")
            
        except Exception as e:
            self.test_results['summary']['failed'] += 1
            self.fail(f"Error en test de rendimiento: {e}")


class TestSystemValidation(unittest.TestCase):
    """Tests adicionales de validaci√≥n del sistema"""
    
    def test_python_version(self):
        """Verificar versi√≥n de Python"""
        import sys
        version = sys.version_info
        self.assertGreaterEqual(version.major, 3, "Requiere Python 3+")
        self.assertGreaterEqual(version.minor, 7, "Requiere Python 3.7+")
        print(f"  ‚úÖ Python {version.major}.{version.minor}.{version.micro}")
    
    def test_required_packages(self):
        """Verificar paquetes requeridos"""
        required_packages = ['numpy', 'opencv-python', 'pillow']
        available_packages = []
        missing_packages = []
        
        for package in required_packages:
            try:
                if package == 'opencv-python':
                    import cv2
                    available_packages.append('opencv-python')
                elif package == 'pillow':
                    import PIL
                    available_packages.append('pillow')
                else:
                    __import__(package)
                    available_packages.append(package)
            except ImportError:
                missing_packages.append(package)
        
        print(f"  ‚úÖ Paquetes disponibles: {available_packages}")
        if missing_packages:
            print(f"  ‚ö†Ô∏è Paquetes faltantes: {missing_packages}")
        
        # No fallar si faltan paquetes opcionales
        self.assertGreater(len(available_packages), 0, "Al menos un paquete debe estar disponible")
    
    def test_file_permissions(self):
        """Verificar permisos de archivos"""
        temp_dir = tempfile.mkdtemp(prefix='sigec_permissions_test_')
        
        try:
            # Probar escritura
            test_file = os.path.join(temp_dir, 'test_write.txt')
            with open(test_file, 'w') as f:
                f.write('test')
            
            # Probar lectura
            with open(test_file, 'r') as f:
                content = f.read()
            
            self.assertEqual(content, 'test', "Lectura/escritura debe funcionar")
            print("  ‚úÖ Permisos de archivos correctos")
            
        finally:
            import shutil
            shutil.rmtree(temp_dir, ignore_errors=True)


def run_backend_integration_tests():
    """Ejecutar todos los tests de integraci√≥n backend"""
    print("=" * 70)
    print("üöÄ EJECUTANDO TESTS DE INTEGRACI√ìN BACKEND")
    print("=" * 70)
    
    # Crear suite de tests
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()
    
    # Agregar tests principales
    suite.addTests(loader.loadTestsFromTestCase(BackendIntegrationTestSuite))
    suite.addTests(loader.loadTestsFromTestCase(TestSystemValidation))
    
    # Ejecutar tests
    runner = unittest.TextTestRunner(verbosity=2, stream=sys.stdout)
    result = runner.run(suite)
    
    # Mostrar resumen
    print("\n" + "=" * 70)
    print("üìä RESUMEN DE EJECUCI√ìN")
    print("=" * 70)
    print(f"Tests ejecutados: {result.testsRun}")
    print(f"Errores: {len(result.errors)}")
    print(f"Fallos: {len(result.failures)}")
    print(f"Saltados: {len(result.skipped) if hasattr(result, 'skipped') else 0}")
    
    if result.errors:
        print("\n‚ùå ERRORES:")
        for test, error in result.errors:
            print(f"  - {test}: {error.split(chr(10))[0]}")
    
    if result.failures:
        print("\n‚ùå FALLOS:")
        for test, failure in result.failures:
            print(f"  - {test}: {failure.split(chr(10))[0]}")
    
    success = len(result.errors) == 0 and len(result.failures) == 0
    
    if success:
        print("\nüéâ TODOS LOS TESTS PASARON EXITOSAMENTE")
    else:
        print("\n‚ö†Ô∏è ALGUNOS TESTS FALLARON")
    
    return success


if __name__ == "__main__":
    success = run_backend_integration_tests()
    sys.exit(0 if success else 1)